# @package _global_

# to execute this experiment run:
# python run.py experiment=f_gan_baseline

defaults:
  - override /trainer: f_gan.yaml
  - override /model: GAN.yaml
  - override /datamodule: null
  - override /callbacks: null
  - override /logger: wandb.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 42

datamodule:
  _target_: src.datamodules.fgan_multiple_class_mnist_datamodule.MNISTDataModule
  data_dir: ${data_dir} 
  batch_size: 64
  train_val_test_split: [55_000, 5_000, 10_000]
  num_workers: 0
  pin_memory: False
  chosen_class:
  - 0
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
trainer:
    min_epochs: 1
    max_epochs: 50
    gpus: 0
    # gradient_clip_val: 1
model:
    batch_size: ${datamodule.batch_size}
    lr: 0.0002
    hidden_dim: 64
    latent_dim: 100

callbacks:
  upload_code_as_artifact:
    _target_: src.callbacks.wandb_callbacks.UploadCodeAsArtifact
    code_dir: ${work_dir}/src

  upload_ckpts_as_artifact:
    _target_: src.callbacks.wandb_callbacks.UploadCheckpointsAsArtifact
    ckpt_dir: "checkpoints/"
    upload_best_only: True 

  log_generated_images:
    _target_: src.callbacks.wandb_callbacks.LogGeneratedImages
    num_samples: 8

  watch_model_f_gan:
    _target_: src.callbacks.wandb_callbacks.WatchModelFGan
    log: "all"
    log_freq: 100

test_after_training: False

name: f_gan_multiple_class_baseline

